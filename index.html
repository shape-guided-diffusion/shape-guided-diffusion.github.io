<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Shape Guided Diffusion with Inside-Outside Attention</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img width="64px" src="static/favicon.png">
            Shape Guided Diffusion <br> with Inside-Outside Attention
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=_kJ-zUYAAAAJ&hl=en">Dong Huk Park</a><sup>1*</sup>,
          	</span>
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~graceluo/">Grace Luo</a><sup>1*</sup>,
          	</span>
          	<span class="author-block">
              Clayton Toste<sup>1</sup>,
          	</span>
          	<span class="author-block">
              <a href="https://scholar.google.com/citations?user=X0EXfT8AAAAJ&hl=en">Samaneh Azadi</a><sup>2</sup>,
          	</span>
          	<br>
          	<span class="author-block">
              <a href="https://xh-liu.github.io/">Xihui Liu</a><sup>1, 3</sup>,
          	</span>
          	<span class="author-block">
              Maka Karalashvili<sup>4</sup>,
          	</span>
          	<span class="author-block">
              <a href="https://anna-rohrbach.net/">Anna Rohrbach</a><sup>1</sup>,
          	</span>
          	<span class="author-block">
              <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a><sup>1</sup>,
          	</span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Berkeley,</span>
            <br>
            <span class="author-block"><sup>2</sup>Meta AI,</span>
            <span class="author-block"><sup>3</sup>The University of Hong Kong,</span>
            <span class="author-block"><sup>4</sup>BMW Group</span>
            <br>
            <span class="is-size-6">*Denotes equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2212.00210"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image">
	  	  <img src="static/figures/teaser.png">
	    </figure>
      <span class="is-size-6 has-text-centered">
        When a target object silhouette is available to guide the image editing process existing methods often generate objects that are poorly aligned with the given shape. We propose Shape-Guided Diffusion, a training-free method which produces shape-faithful, text-aligned, realistic objects, by using a novel Inside-Outside Attention mechanism to align the generated content with the target silhouette.
      </span>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="has-text-centered">Examples of shape-guided edits synthesized by our method.</div>
      <div id="results-carousel-face" class="carousel results-carousel" data-slides-to-show="1">
        <div class="item-1">
        <img src="static/figures/carousel/graffiti_truck_success.png">
        </div>
        <div class="item-2">
        <img src="static/figures/carousel/lego_truck_success.png">
        </div>
        <div class="item-3">
      	<img src="static/figures/carousel/pbj_sandwich_success.png">
        </div>
        <div class="item-4">
        <img src="static/figures/carousel/tortilla_sandwich_success.png">
        </div>
        <div class="item-5">
        <img src="static/figures/carousel/iridescent_bird_success.png">
        </div>
        <div class="item-6">
        <img src="static/figures/carousel/blue_yellow_bird_success.png">
        </div>
        <div class="item-7">
        <img src="static/figures/carousel/inflatable_boat_success.png">
        </div>
        <div class="item-8">
        <img src="static/figures/carousel/candy_boat_success.png">
        </div>
        <div class="item-9">
        <img src="static/figures/carousel/futuristic_horse_success.png">
        </div>
        <div class="item-10">
        <img src="static/figures/carousel/gold_horse_success.png">
        </div>
        <div class="item-11">
        <img src="static/figures/carousel/tie_cat_success.png">
        </div>
        <div class="item-12">
        <img src="static/figures/carousel/leopard_cat_success.png">
        </div>
        <div class="item-13">
        <img src="static/figures/carousel/glitter_kite_success.png">
        </div>
        <div class="item-14">
        <img src="static/figures/carousel/origami_kite_success.png">
        </div>
        <div class="item-15">
        <img src="static/figures/carousel/sunglasses_bear_success.png">
        </div>
        <div class="item-16">
        <img src="static/figures/carousel/stuffed_bear_success.png">
        </div>
        <div class="item-17">
        <img src="static/figures/carousel/colorful_dog_success.png">
        </div>
        <div class="item-18">
        <img src="static/figures/carousel/floral_dog_success.png">
        </div>
        <div class="item-19">
        <img src="static/figures/carousel/holi_elephant_success.png">
        </div>
        <div class="item-20">
        <img src="static/figures/carousel/christmas_elephant_success.png">
        </div>
    </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Shape can specify key object constraints, yet existing text-to-image diffusion models ignore this cue and synthesize objects that are incorrectly scaled, cut off, or replaced with background content. We propose a training-free method, Shape-Guided Diffusion, which uses a novel Inside-Outside Attention mechanism to constrain the cross-attention (and self-attention) maps such that prompt tokens (and pixels) referring to the inside of the shape cannot attend outside the shape, and vice versa.
          </p>
          <p>
            To demonstrate the efficacy of our method, we propose a new image editing task where the model must replace an object specified by its mask and a text prompt. We curate a new ShapePrompts benchmark based on MS-COCO and achieve SOTA results in shape faithfulness, text alignment, and realism according to both quantitative metrics and human preferences.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- A -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Shape-Guided Diffusion</h2>
        <div class="content has-text-justified">
          <p>
            Given two text prompts, one that describes the original object ("dog") and one that describes the desired object ("dog wearing a colorful shirt"), we modify a pretrained diffusion model such that it respects the objectâ€™s original shape during editing. To do this, we take the object mask as an additional input and apply Inside-Outside Attention to both the inversion and generation processes to independently synthesize the object and background.
          </p>
        </div>
        <figure class="image">
	  	  <img src="static/figures/overall-pipeline.png">
	  	</figure>
      </div>
    </div>
    <!--/ A -->
    <br>
    <!-- B -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Inside-Outside Attention</h2>
        <div class="content has-text-justified">
          <p>
            In our Inside-Outside Attention mechanism, we modify the attention maps in both the cross-attention and self-attention layers. In the cross-attention layer depending on whether the text embedding refers to the inside or outside the object, we constrain the attention map M according to the object mask or the inverted object mask to produce M'. In the self-attention layer we perform a similar operation on the inside and outside pixel embeddings.
          </p>
          <figure class="image">
        	<img style="width:50vw !important;" src="static/figures/cross-attn.png">
          </figure>
        </div>
      </div>
    </div>
    <!--/ B -->
    <br>
    <!-- C -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Additional Editing Capabilities</h2>
        
        <div class="content has-text-justified">
          <p>
            <b>Inter-Class Edits.</b> Our method can perform both intra- and inter-class edits to the same object. For example, we can both transform a cow into a "cow covered in gold and diamond chains" and into a "sheep."
          </p>
          <figure class="image">
	  		<img style="width:50vw !important;" src="static/figures/inter-class-edit.png">
	  	  </figure>
        </div>
        
        <div class="content has-text-justified">
          <p>
            <b>Background Edits.</b> Our method is not only able to edit objects but also backgrounds. We demonstrate editing the background in a real image to different locations, seasons, and times of day while preserving the bus.
          </p>
          <figure class="image">
	  	  	<img src="static/figures/background-edit.png">
	  	  </figure>
        </div>

        <div class="content has-text-justified">
          <p>
            <b>Simultaneous Inside-Outside Edits.</b> Since our method allows us to localize and separate the editing of the object and background, we can simultaneously edit both with two different prompts. This property allows us to maintain the relation of the object with the scene (the silhouette and exact position of the horse grazing on grass) and significantly modify both objects (converting the horse to a "futuristic biomechanical robot" and the background to the "Metropolitan Museum of Art.")
          </p>
          <figure class="image">
	  	  	<img src="static/figures/simultaneous-edit.png">
	  	  </figure>
        </div>

        <div class="content has-text-justified">
          <p>
            <b>Inferred Segmentation Mask Edits.</b> We also demonstrate that our method also works on automatically inferred masks predicted by MaskFormer, an off-the-shelf segmentation model. Note how our method is able to handle masks with reflections, multiple disjoint objects, and multiple overlapping objects. In a real world setting, this means that an off-the-shelf segmentation model can be used to infer the shape, allowing the user to only input an image and prompt referencing the object they would like to edit.
          </p>
          <figure class="image">
	  	  	<img src="static/figures/inf-mask.png">
	  	  </figure>
        </div>

      </div>
    </div>
    <!--/ C -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2022shape,
  author    = {Park, Dong Huk and Luo, Grace and Toste, Clayton and Azadi, Samaneh and Liu, Xihui and Karalashvili, Maka and Rohrbach, Anna and Darrell, Trevor},
  title     = {Shape Guided Diffusion with Inside-Outside Attention},
  journal   = {arXiv},
  year      = {2022},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. We build on top of the source code from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
